# -*- coding: utf-8 -*-
"""Inmersion_en_Datos_Aula.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17reMhSKSvUWIn1hl2CAbNNU0z-l8IPgo

Bienvenidos
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd

inmuebles = pd.read_csv('/content/drive/MyDrive/inmuebles_bogota.csv')
inmuebles.head()

inmuebles.shape

inmuebles.columns

columnas = {'Baños':'Banos','Área':'Area'}
inmuebles =  inmuebles.rename (columns = columnas)
inmuebles.sample(10)

inmuebles.info()

inmuebles.iloc[300]

inmuebles['Valor'][300]

inmuebles['Valor'][300:305]

type(inmuebles['Valor'][300:305])

inmuebles.Area.mean()

inmuebles.sample(100)

inmuebles.Barrio == 'Chico Reservado'

sum(inmuebles.Barrio == 'Chico Reservado')

inmuebles_chico = (inmuebles.Barrio == 'Chico Reservado')
type (inmuebles_chico)

chico_reservado = inmuebles [inmuebles_chico]
chico_reservado

chico_reservado.Area.mean()

inmuebles.Area.mean()

len(inmuebles.Barrio.value_counts())

inmuebles.Barrio.value_counts()

len(inmuebles.UPZ.value_counts())

inmuebles.UPZ.value_counts()

inmuebles_barrio = inmuebles.Barrio.value_counts()
inmuebles_barrio.plot.bar()

inmuebles_barrio.head(10).plot.bar()



"""**Desafio**
1. Promedio de area de todos los inmuebles en los barrios en el dataset. El top 10 plotearlo
2. Consultar otros datos estadisticos conteo, median, valores minimo maximo

**AULA 2**
"""

inmuebles.sample(5)

inmuebles.info()

type(inmuebles.Valor[0])

inmuebles.Valor[0]+inmuebles.Valor[1]

"""vemos que la columna **Valor** es un string, entonces convertiremos a numero float paso a paso"""

inmuebles.Valor[0].split()

inmuebles.Valor.str.split()

valor = inmuebles.Valor.str.split(expand = True)
inmuebles['Moneda']= valor [0]
inmuebles['Precio']= valor [1]
inmuebles.sample(3)

inmuebles.info()

"""**Siguen siendo objetos** Precio = object"""

inmuebles['Precio'] = inmuebles['Precio'].str.replace('.','',regex=True)

inmuebles[['Precio','Barrio']]

"""Eliminé los **caracteres especiales** pero aun sigue siendo Object



"""

inmuebles['Precio_Millon'] = inmuebles.Precio.astype('float')/1000000
inmuebles.info()

"""***CONSEGUIDO*** se convirtio de object a float la columna de valor y su precio se ve en millones ahora"""

inmuebles.describe()

pd.set_option('display.precision',2)
pd.set_option('display.float_format', lambda x: '%.2f' % x)
inmuebles.describe()

inmuebles.loc[inmuebles. Habitaciones == 110]

inmuebles['Precio_Millon'].plot.hist(bins=50)

inmuebles['Precio_Millon'].plot.hist(bins=10)

"""A mas 'bins' mas precision en las barras del histograma

**seaborn documentation** para hacer graficas mas precisas y exactas con mas gama de opciones

**matplotlib** similar pero mas basica
"""

import matplotlib.pyplot as plt
import seaborn as sns

plt.figure(figsize=(10,6))
grafica = sns.histplot(data=inmuebles, x='Precio_Millon',kde=True, hue='Tipo')
grafica.set_title('Distribucion de Valores de los inmuebles de Bogota')
plt.xlim((50,1000))

plt.show()

"""1.   Estudiar mejor el histograma de valores, seleccionar 3 tipos de inmuebles (Refinar grafico: Titulo, aumentar tamano de labels, colores, conclusion de la informacion)
2.   Precio del m2 por barrio y hacer el grafico mas adecuado para esta nueva variable

**CLASE 3**
"""

inmuebles['Valor_m2_Millon'] = inmuebles ['Precio_Millon']/inmuebles['Área']
inmuebles.head(3)

inmuebles.groupby('Barrio').mean()

"""Realicemos la comparacion haciendo un calculo mas preciso"""

datos_barrio =  inmuebles.groupby('Barrio').sum()
datos_barrio

datos_barrio['Valor_m2_Barrio'] = datos_barrio['Precio_Millon']/datos_barrio['Área']
datos_barrio

m2_barrio = dict(datos_barrio['Valor_m2_Barrio'])

inmuebles['Valor_m2_Barrio'] = inmuebles['Barrio']
inmuebles['Valor_m2_Barrio'] = inmuebles['Valor_m2_Barrio'].map(m2_barrio)
inmuebles.head(5)

top_barrios = inmuebles['Barrio'].value_counts()[:10].index

top_barrios

datos_barrio.reset_index(inplace=True)
datos_barrio

datos_barrio.query('Barrio in @top_barrios')

plt.figure(figsize=(10,8))
ax = sns.barplot(x="Barrio", y="Valor_m2_Barrio", data=datos_barrio.query('Barrio in @top_barrios'))
ax.tick_params(axis= 'x',rotation=45)

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Valor_m2_Millon", data=inmuebles.query('Barrio in @top_barrios'))
ax.tick_params(axis= 'x',rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Valor_m2_Millon", data=inmuebles.query('Barrio in @top_barrios & Valor_m2_Millon < 15'))
ax.tick_params(axis= 'x',rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Area", data=inmuebles.query('Barrio in @top_barrios & Area < 350'))
ax.tick_params(axis= 'x',rotation=45)
plt.show()

plt.figure(figsize=(10,8))
ax = sns.boxplot(x="Barrio", y="Precio_Millon", data=inmuebles.query('Barrio in @top_barrios & Precio_Millon < 2000'))
ax.tick_params(axis= 'x',rotation=45)
plt.show()



"""Vamos a traer datos estadisticos de la ciudad de Bogota, directamente del DANE y vamos a ver como estos datos nos ayudarian en inclusion de nuevas variables para el calculo de los inmuebles de la ciudad de Bogota.
Encuesta Multiproposito de Bogota para obtener informacion socio-economica y de entorno urbano de los habitantes de Bogota para la formulacion, seguimiento y evaluacion de las politicas distritales.
https://microdatos.dane.gov.co/index.php/catalog/743

"""

datos_raw = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Identificación (Capítulo A).csv', sep = ';',encoding = 'latin 1')
datos_raw.head()

datos_raw.shape

datos_raw = datos_raw.loc[datos_raw.MPIO == 11001]
datos_raw.shape

datos_b = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Datos de la vivenda y su entorno (Capítulo B).csv', sep = ';',encoding = 'latin 1')
datos_c = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Condiciones habitacionales del hogar (Capítulo C).csv', sep = ';',encoding = 'latin 1')
datos_e = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Composición del hogar y demografía (Capítulo E).csv', sep = ';',encoding = 'latin 1')
datos_h = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Educación (Capítulo H).csv', sep = ';',encoding = 'latin 1')
datos_l = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Percepción sobre las condiciones de vida y el desempeño institucional (Capítulo L).csv', sep = ';',encoding = 'latin 1')
datos_k = pd.read_csv('/content/drive/MyDrive/archivos-dane/archivos-dane/Fuerza de trabajo (Capítulo K).csv', sep = ';',encoding = 'latin 1')

datos_dane = pd.merge(datos_raw,datos_b,on = 'DIRECTORIO', how = 'left')
datos_dane.shape

datos_dane = pd.merge(datos_dane,datos_c,on = 'DIRECTORIO', how = 'left')
datos_dane.shape

datos_dane = pd.merge(datos_dane,datos_e,on = 'DIRECTORIO', how = 'left')
datos_dane.shape

datos_dane.info()



"""**DESAFIO**


1.   Dar un vistazo a los datos del DANE, entender estas variables conceptualmente para entender mejor el contexto de esta base.
2.   Organizar tu notebook para que tu proyecto quede mejor presentado.


"""

datos_dane = pd.read_csv('/content/drive/MyDrive/datos_dane.csv')
datos_dane.head()

datos_dane.shape

dic_dane = {
       'NVCBP4':'CONJUNTO_CERRADO',
       'NVCBP14A':'FABRICAS_CERCA', 'NVCBP14D':'TERMINALES_BUS', 'NVCBP14E':'BARES_DISCO',
       'NVCBP14G':'OSCURO_PELIGROSO', 'NVCBP15A':'RUIDO', 'NVCBP15C':'INSEGURIDAD',
       'NVCBP15F':'BASURA_INADECUADA', 'NVCBP15G':'INVASION','NVCBP16A3':'MOV_ADULTOS_MAYORES',
       'NVCBP16A4':'MOV_NINOS_BEBES',
       'NPCKP17':'OCUPACION','NPCKP18':'CONTRATO','NPCKP23':'SALARIO_MES',
       'NPCKP44A':'DONDE_TRABAJA', 'NPCKPN62A':'DECLARACION_RENTA',
       'NPCKPN62B':'VALOR_DECLARACION', 'NPCKP64A':'PERDIDA_TRABAJO_C19',
       'NPCKP64E':'PERDIDA_INGRESOS_C19',
       'NHCCP3':'TIENE_ESCRITURA', 'NHCCP6':'ANO_COMPRA', 'NHCCP7':'VALOR_COMPRA', 'NHCCP8_1':'HIPOTECA_CRED_BANCO',
       'NHCCP8_2':'OTRO_CRED_BANCO', 'NHCCP8_3':'CRED_FNA', 'NHCCP8_6':'PRESTAMOS_AMIGOS',
       'NHCCP8_7':'CESANTIAS', 'NHCCP8_8':'AHORROS', 'NHCCP8_9':'SUBSIDIOS',
       'NHCCP9':'CUANTO_PAGARIA_MENSUAL', 'NHCCP11':'PLANES_ADQUIRIR_VIVIENDA',
       'NHCCP11A':'MOTIVO_COMPRA', 'NHCCP12':'RAZON_NO_ADQ_VIV', 'NHCCP41':'TIENE_CARRO','NHCCP41A':'CUANTOS_CARROS',
       'NHCCP47A':'TIENE_PERROS', 'NHCCP47B':'TIENE_GATOS', 'NHCLP2A':'VICTIMA_ATRACO', 'NHCLP2B':'VICTIMA_HOMICIDIO',
       'NHCLP2C':'VICTIMA_PERSECUSION',
       'NHCLP2E':'VICTIMA_ACOSO', 'NHCLP4':'COMO_VIVE_ECON', 'NHCLP5':'COMO_NIVEL_VIDA',
       'NHCLP8AB':'REACCION_OPORTUNA_POLICIA', 'NHCLP8AE':'COMO_TRANSPORTE_URBANO', 'NHCLP10':'SON_INGRESOS_SUFICIENTES',
       'NHCLP11':'SE_CONSIDERA_POBRE', 'NHCLP29_1A':'MED_C19_TRABAJO',
       'NHCLP29_1C':'MED_C19_CAMBIO_VIVIENDA', 'NHCLP29_1E':'MED_C19_ENDEUDAMIENTO',
       'NHCLP29_1F':'MED_C19_VENTA_BIENES','NPCHP4':'NIVEL_EDUCATIVO'
       }

datos_dane = datos_dane.rename(columns=dic_dane)
datos_dane.columns

datos_dane.info()

datos_dane.groupby('NOMBRE_ESTRATO')[['CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].mean().head()

datos = datos_dane[['NOMBRE_ESTRATO','CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].replace(2,0)
datos

datos_tratados = datos.groupby('NOMBRE_ESTRATO')[['CONJUNTO_CERRADO','INSEGURIDAD','TERMINALES_BUS','BARES_DISCO','RUIDO','OSCURO_PELIGROSO','SALARIO_MES','TIENE_ESCRITURA','PERDIDA_TRABAJO_C19','PERDIDA_INGRESOS_C19','PLANES_ADQUIRIR_VIVIENDA']].mean()
datos_tratados

pd.merge(inmuebles,datos_tratados, left_on='UPZ',right_on='NOMBRE_ESTRATO',how='left')

datos_ml=pd.merge(inmuebles,datos_tratados, left_on='UPZ',right_on='NOMBRE_ESTRATO',how='left')
datos_ml.info()

upz = pd.read_csv('/content/drive/MyDrive/cod_upz.csv')
datos_ml = pd.merge(datos_ml,upz,left_on='UPZ',right_on='NOMBRE_ESTRATO',how='inner')
datos_ml.head()

datos_ml.shape

datos_ml.info()

plt.figure(figsize=(10,8))
sns.boxplot(data=datos_ml, y='Precio_Millon')
plt.show()

datos_ml.query('Precio_Millon > 5000 |Precio_Millon <60')

datos_ml = datos_ml.query('Precio_Millon < 1200 & Precio_Millon > 60')
datos_ml

plt.figure(figsize=(10,8))
sns.boxplot(data=datos_ml, y='Precio_Millon')
plt.show()

datos_ml['SALARIO_ANUAL_MI'] = datos_ml['SALARIO_MES']*12/1000000
datos_ml['SALARIO_ANUAL_MI']

plt.figure(figsize=(10,8))
sns.scatterplot(data=datos_ml, x= 'SALARIO_ANUAL_MI', y='Valor_m2_Millon')
plt.ylim((0,15))
plt.show()

datos_ml.corr()

plt.figure(figsize=(18, 8))
#https://www.tylervigen.com/spurious-correlations
#mascara = np.triu(np.ones_like(datos_ml.corr(), dtype=bool)) mask=mascara,
heatmap = sns.heatmap(datos_ml.corr(), vmin=-1, vmax=1, annot=True, cmap='BrBG')
heatmap.set_title('CorrelaciÃ³n de las variables', fontdict={'fontsize':18}, pad=16);

from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split
X = datos_ml[['COD_UPZ_GRUPO']]
y = datos_ml[['Precio_Millon']]
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 99)

X_train

X_test

y_train

y_test

modelo = LinearRegression()
modelo.fit(X_train, y_train)
LinearRegression()

y_predict_test = modelo.predict(X_test)

from sklearn.metrics import mean_absolute_error, r2_score

baseline_mae = mean_absolute_error(y_test,y_predict_test)
baseline_r2 = r2_score(y_test, y_predict_test)
print(baseline_mae,baseline_r2)

X = datos_ml[['COD_UPZ_GRUPO','Habitaciones','Baños','CONJUNTO_CERRADO','SALARIO_ANUAL_MI','TIENE_ESCRITURA']]

Y = datos_ml["Precio_Millon"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 99)
modelo_1 = LinearRegression()
modelo_1.fit(X_train, y_train)
y_predict_test = modelo_1.predict(X_test)
y_predict_train = modelo_1.predict(X_train)
mae_test = mean_absolute_error(y_test, y_predict_test)
r2_test = r2_score(y_test, y_predict_test)
mae_train = mean_absolute_error(y_train, y_predict_train)
r2_train = r2_score(y_train, y_predict_train)
print(mae_test,r2_test)
print(mae_train,r2_train)

X = datos_ml[['COD_UPZ_GRUPO','Habitaciones','Baños','CONJUNTO_CERRADO','SALARIO_ANUAL_MI','TIENE_ESCRITURA']]

Y = datos_ml["Precio_Millon"]

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 99)
modelo_1 = LinearRegression()
modelo_1.fit(X_train, y_train)
y_predict_test = modelo_1.predict(X_test)
y_predict_train = modelo_1.predict(X_train)
mae_test = mean_absolute_error(y_test, y_predict_test)
r2_test = r2_score(y_test, y_predict_test)
mae_train = mean_absolute_error(y_train, y_predict_train)
r2_train = r2_score(y_train, y_predict_train)
print(mae_test,r2_test)
print(mae_train,r2_train)

modelo_1.predict([[816,3,2,1,50,1]])